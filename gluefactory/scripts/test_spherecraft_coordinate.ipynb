{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "657f18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"] = \"1\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "585bd84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img, kpts, sph=False, color=(255, 0, 255), radius=1, thickness=5):\n",
    "    \"\"\"\n",
    "    Draws keypoints on an image and displays it.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The input image in BGR format (as read by cv2).\n",
    "        kpts_spherical (np.ndarray): Keypoints in spherical coordinates (phi, theta).\n",
    "        color (tuple): BGR color for the keypoints.\n",
    "        radius (int): Radius of the circles representing keypoints.\n",
    "        thickness (int): Thickness of the circle outline.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    # Convert spherical keypoints to pixel coordinates in the image\n",
    "    if sph:\n",
    "        pixel_coords = standard_spherical_to_pixel(kpts, w, h)\n",
    "    else:\n",
    "        pixel_coords = kpts\n",
    "\n",
    "    # Draw each keypoint as a circle on the image\n",
    "    for point in pixel_coords:\n",
    "        # Get integer coordinates for drawing\n",
    "        x, y = int(round(point[0])), int(round(point[1]))\n",
    "        cv2.circle(img, (x, y), radius, color, thickness)\n",
    "\n",
    "    # --- Display the image using Matplotlib ---\n",
    "    # Convert the image from BGR (OpenCV's default) to RGB for correct color display\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create a plot to show the image\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(\"Image with Plotted Keypoints\")\n",
    "    plt.axis('off')  # Hide the axes for a cleaner look\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44412a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_depth(p):\n",
    "    d = cv2.imread(str(p), cv2.IMREAD_UNCHANGED)\n",
    "    if d.ndim == 3: d = d[...,0]\n",
    "    return d.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4985a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pose_and_get_c2w_matrix(filepath):\n",
    "    \"\"\"Reads a pose from a specific .dat file format.\n",
    "\n",
    "    Each file contains the rotation matrix R stored as a 3 x 3 matrix that, following convention, \n",
    "    encodes the transformation from world to camera coordinate system. However, here the vector t \n",
    "    does not follow convention and represents the camera position in world coordinate system. This \n",
    "    is convenient to compute distances between cameras and determine neighborhood.\n",
    "\n",
    "    1. R is a 3x3 matrix from world-to-camera. This means P_camera = R @ P_world.\n",
    "    2. t (as stored in the file) represents the camera position in the world coordinate system. \n",
    "    This means t is what we typically call the camera center, C.\n",
    "\n",
    "    Args:\n",
    "        filepath: Path to the .dat file.\n",
    "\n",
    "    Returns:\n",
    "        A 4x4 Camera-to-World (C2W) matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the 3x3 rotation matrix, skipping the first 2 header lines\n",
    "    # and reading only the 3 subsequent lines.\n",
    "    R_w2c = np.loadtxt(filepath, skiprows=2, max_rows=3)\n",
    "    \n",
    "    # Load the 3x1 translation vector, skipping all lines before it.\n",
    "    # (2 header lines + 3 matrix rows + 't' marker = 6 lines)\n",
    "    C_world = np.loadtxt(filepath, skiprows=6)\n",
    "\n",
    "    # --- Convert [R_w2c | C] to a 4x4 C2W matrix ---\n",
    "    # The rotation part of a C2W matrix is the inverse (transpose) of a W2C rotation.\n",
    "    R_c2w = R_w2c.T\n",
    "    \n",
    "    # The translation part of a C2W matrix is simply the camera center C.\n",
    "    t_c2w = C_world\n",
    "    \n",
    "    # Assemble the 4x4 matrix\n",
    "    pose_c2w = np.eye(4)\n",
    "    pose_c2w[:3, :3] = R_c2w\n",
    "    pose_c2w[:3, 3] = t_c2w\n",
    "\n",
    "    pose_w2c = np.eye(4)\n",
    "    pose_w2c[:3, :3] = R_w2c\n",
    "    pose_w2c[:3, 3] = -R_w2c.dot(t_c2w)\n",
    "\n",
    "    return pose_c2w, pose_w2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35442374",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 2048\n",
    "H = 1024\n",
    "\n",
    "def standard_spherical_to_pixel(kpts_sph_np, W, H):\n",
    "    \"\"\"\n",
    "    Converts standard spherical coordinates to pixel coordinates.\n",
    "    phi: longitude [-pi, pi] -> x [0, W]\n",
    "    theta: latitude [-pi/2, pi/2] -> y [0, H]\n",
    "    \"\"\"\n",
    "    phi = kpts_sph_np[:, 0]\n",
    "    theta = kpts_sph_np[:, 1]\n",
    "\n",
    "    # Normalize phi to [0, 1] and theta to [0, 1] and Scale to pixel coordinates\n",
    "    px = (phi / (2 * np.pi) + 0.5) * (W - 1) - 0.5\n",
    "    py = (-theta / np.pi + 0.5) * (H - 1) - 0.5\n",
    "    \n",
    "    return np.stack([px, py], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ce4622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unproject_spherical(uv, d, w, h):\n",
    "    u = uv[:, 0].astype(float)\n",
    "    v = uv[:, 1].astype(float)\n",
    "    r = d.squeeze().astype(float)\n",
    "    phi = (v + 0.5) * np.pi / h\n",
    "    theta = (1.0 - (u + 0.5) / w) * (2.0 * np.pi)\n",
    "    x = r * np.cos(theta) * np.sin(phi)\n",
    "    y = r * np.sin(theta) * np.sin(phi)\n",
    "    z = r * np.cos(phi)\n",
    "    return np.stack([x, y, z], axis=1)\n",
    "\n",
    "\n",
    "def project_spherical(pts, w, h):\n",
    "    x, y, z = pts[:, 0], pts[:, 1], pts[:, 2]\n",
    "\n",
    "    d = np.linalg.norm(pts, axis=-1)\n",
    "    d_safe = np.clip(d, a_min=1e-8, a_max=None)  # Prevent division by zero\n",
    "\n",
    "    phi = np.arccos(np.clip(z/d_safe, a_min=-1.0, a_max=1.0)) \n",
    "    theta = np.arctan2(y, x) # Shift to [0, 2*pi]\n",
    "    theta = np.remainder(theta, 2.0 * np.pi)\n",
    "\n",
    "    u = (1.0 - theta / (2.0 * np.pi)) * w - 0.5\n",
    "    v = (phi / np.pi) * h - 0.5\n",
    "    \n",
    "    uv = np.stack([u, v], axis=1)\n",
    "    return uv, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c5b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"/data/code/glue-factory/datasets/spherecraft_data/barbershop/images/00000000.jpg\")\n",
    "img2 = cv2.imread(\"/data/code/glue-factory/datasets/spherecraft_data/barbershop/images/00000001.jpg\")\n",
    "depth1 = read_depth(\"/data/code/glue-factory/datasets/spherecraft_data/barbershop/depthmaps/00000000.exr\")\n",
    "depth2 = read_depth(\"/data/code/glue-factory/datasets/spherecraft_data/barbershop/depthmaps/00000001.exr\")\n",
    "\n",
    "kpts1_sph = np.load(\"/data/code/glue-factory/datasets/spherecraft_data/barbershop/features_xfeat_spherical/00000000.npz\")['keypoints']\n",
    "kpts2_sph = np.load(\"/data/code/glue-factory/datasets/spherecraft_data/barbershop/features_xfeat_spherical/00000001.npz\")['keypoints']\n",
    "\n",
    "p0_c2w, p0_w2c = load_pose_and_get_c2w_matrix(\"/data/code/glue-factory/datasets/spherecraft_data/barbershop/extr/00000000.dat\")\n",
    "p1_c2w, p1_w2c = load_pose_and_get_c2w_matrix(\"/data/code/glue-factory/datasets/spherecraft_data/barbershop/extr/00000001.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "203aa5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpts1 = standard_spherical_to_pixel(kpts1_sph, W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b2e795c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kpts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84480b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_N = min(100, len(kpts1))\n",
    "ids_rt = random.sample(range(len(kpts1)), sample_N)\n",
    "uv_rt = kpts1[ids_rt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3850a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_rt = depth1[uv_rt[:,1].astype(int), uv_rt[:,0].astype(int)]\n",
    "pts3d_rt = unproject_spherical(uv_rt, d_rt, W, H)\n",
    "uv_reproj, _ = project_spherical(pts3d_rt, W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d50309a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[586.9989 , 483.16373],\n",
       "       [820.103  , 910.27014],\n",
       "       [803.877  , 599.0131 ],\n",
       "       [292.90872, 533.43787],\n",
       "       [279.7636 , 857.49567]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uv_rt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cbe95da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[586.99890137, 483.16372681],\n",
       "       [820.10302734, 910.2701416 ],\n",
       "       [803.87701416, 599.01312256],\n",
       "       [292.90872192, 533.43786621],\n",
       "       [279.76361084, 857.4956665 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uv_reproj[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24897355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmptyTensorError(Exception):\n",
    "    pass\n",
    "\n",
    "def interpolate_depth(pos, depth):\n",
    "    \"\"\"Interpolates depth values for 2D points using bilinear interpolation.\"\"\"\n",
    "    # Ensure pos is 2xN and convert to integer indices\n",
    "    pos = pos.T[[1, 0]]\n",
    "\n",
    "    h, w = depth.shape\n",
    "    \n",
    "    i = pos[0, :].astype(float)\n",
    "    j = pos[1, :].astype(float)\n",
    "\n",
    "    # Valid corners and indices\n",
    "    i_top_left = np.floor(i).astype(int)\n",
    "    j_top_left = np.floor(j).astype(int)\n",
    "    valid_top_left = np.logical_and(i_top_left >= 0, j_top_left >= 0)\n",
    "\n",
    "    i_top_right = np.floor(i).astype(int)\n",
    "    j_top_right = np.ceil(j).astype(int)\n",
    "    valid_top_right = np.logical_and(i_top_right >= 0, j_top_right < w)\n",
    "\n",
    "    i_bottom_left = np.ceil(i).astype(int)\n",
    "    j_bottom_left = np.floor(j).astype(int)\n",
    "    valid_bottom_left = np.logical_and(i_bottom_left < h, j_bottom_left >= 0)\n",
    "\n",
    "    i_bottom_right = np.ceil(i).astype(int)\n",
    "    j_bottom_right = np.ceil(j).astype(int)\n",
    "    valid_bottom_right = np.logical_and(i_bottom_right < h, j_bottom_right < w)\n",
    "\n",
    "    valid_corners = np.all(\n",
    "        [valid_top_left, valid_top_right, valid_bottom_left, valid_bottom_right], axis=0)\n",
    "\n",
    "    ids = np.arange(pos.shape[1])\n",
    "    ids_valid_corners = ids[valid_corners]\n",
    "    \n",
    "    if ids_valid_corners.size == 0:\n",
    "        raise EmptyTensorError\n",
    "\n",
    "    i_top_left = i_top_left[valid_corners]\n",
    "    j_top_left = j_top_left[valid_corners]\n",
    "    i_top_right = i_top_right[valid_corners]\n",
    "    j_top_right = j_top_right[valid_corners]\n",
    "    i_bottom_left = i_bottom_left[valid_corners]\n",
    "    j_bottom_left = j_bottom_left[valid_corners]\n",
    "    i_bottom_right = i_bottom_right[valid_corners]\n",
    "    j_bottom_right = j_bottom_right[valid_corners]\n",
    "    \n",
    "    # Check depth validity\n",
    "    valid_depth = np.all(\n",
    "        [\n",
    "            depth[i_top_left, j_top_left] > 0,\n",
    "            depth[i_top_right, j_top_right] > 0,\n",
    "            depth[i_bottom_left, j_bottom_left] > 0,\n",
    "            depth[i_bottom_right, j_bottom_right] > 0\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    ids = ids_valid_corners[valid_depth]\n",
    "    ids_valid_depth = deepcopy(ids)\n",
    "\n",
    "    if ids.size == 0:\n",
    "        raise EmptyTensorError\n",
    "\n",
    "    i = i[ids]\n",
    "    j = j[ids]\n",
    "\n",
    "    i_top_left = i_top_left[valid_depth]\n",
    "    j_top_left = j_top_left[valid_depth]\n",
    "    i_top_right = i_top_right[valid_depth]\n",
    "    j_top_right = j_top_right[valid_depth]\n",
    "    i_bottom_left = i_bottom_left[valid_depth]\n",
    "    j_bottom_left = j_bottom_left[valid_depth]\n",
    "    i_bottom_right = i_bottom_right[valid_depth]\n",
    "    j_bottom_right = j_bottom_right[valid_depth]\n",
    "\n",
    "    # Interpolation\n",
    "    dist_i = i - i_top_left\n",
    "    dist_j = j - j_top_left\n",
    "    w_top_left = (1 - dist_i) * (1 - dist_j)\n",
    "    w_top_right = (1 - dist_i) * dist_j\n",
    "    w_bottom_left = dist_i * (1 - dist_j)\n",
    "    w_bottom_right = dist_i * dist_j\n",
    "\n",
    "    interpolated_depth = (w_top_left * depth[i_top_left, j_top_left] +\n",
    "                          w_top_right * depth[i_top_right, j_top_right] +\n",
    "                          w_bottom_left * depth[i_bottom_left, j_bottom_left] +\n",
    "                          w_bottom_right * depth[i_bottom_right, j_bottom_right])\n",
    "\n",
    "    pos_valid = pos[:, ids]\n",
    "    pos_valid = pos_valid[[1, 0]].T\n",
    "\n",
    "    return [interpolated_depth, pos_valid, ids, ids_valid_corners, ids_valid_depth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de8b63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_points3d(points3d0: np.ndarray, pose01: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Warps 3D points using a SE3 pose.\"\"\"\n",
    "    points3d0_homo = np.concatenate([points3d0, np.ones((points3d0.shape[0], 1))], axis=1)\n",
    "    points3d01_homo = np.einsum('jk,nk->nj', pose01, points3d0_homo)\n",
    "    return points3d01_homo[:, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edc3953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def warp_se3_spherical(kpts0: np.ndarray, params: dict) -> tuple:\n",
    "    \"\"\"Warps 2D keypoints from one spherical image to another using 3D transformation and validation.\"\"\"\n",
    "    pose01 = params['pose01']\n",
    "    depth0 = params['depth0'].squeeze()\n",
    "    depth1 = params['depth1'].squeeze()\n",
    "    W, H = params['width'], params['height']\n",
    "    abs_tol = params.get('abs_tol', 0.05)\n",
    "    rel_tol = params.get('rel_tol', 0.02)\n",
    "\n",
    "    try:\n",
    "        # 1) Get depth for keypoints\n",
    "        z0, k0v, ids0, _, _ = interpolate_depth(kpts0, depth0)\n",
    "    except EmptyTensorError:\n",
    "        logging.warning(\"No valid keypoints after img0 depth check.\")\n",
    "        return kpts0, kpts0, np.empty(0, dtype=np.long), np.empty(0, dtype=np.long)\n",
    "\n",
    "    # 2) Unproject -> warp -> project\n",
    "    pts3d_0 = unproject_spherical(k0v, z0, W, H)\n",
    "    pts3d_1 = warp_points3d(pts3d_0, pose01)\n",
    "    uv1_pred, z1_proj = project_spherical(pts3d_1, W, H)\n",
    "\n",
    "    try:\n",
    "        # 3) Depth check img1\n",
    "        z1i, k1v, ids1, _, _ = interpolate_depth(uv1_pred, depth1)\n",
    "    except EmptyTensorError:\n",
    "        logging.warning(\"All warped keypoints invalid in img1.\")\n",
    "        return kpts0, uv1_pred, ids0, ids1\n",
    "        \n",
    "    # 4) Occlusion check (depth consistency)\n",
    "    abs_diff = np.abs(z1_proj[ids1] - z1i)\n",
    "    rel_diff = abs_diff / np.clip(z1i, a_min=1e-6, a_max=None)\n",
    "    mask = (abs_diff < abs_tol) & (rel_diff < rel_tol)\n",
    "    \n",
    "    # Filter points based on the mask\n",
    "    final_ids = ids0[ids1][mask]\n",
    "    k0_final = k0v[ids1][mask]\n",
    "    k1_final = k1v[mask]\n",
    "    \n",
    "    # 5) Handle spherical wrap-around\n",
    "    u0n = k0_final[:, 0] / (W - 1)\n",
    "    u1n = k1_final[:, 0] / (W - 1)\n",
    "    dn = np.remainder(u1n - u0n + 0.5, 1.0) - 0.5\n",
    "    uc = np.remainder(u0n + dn, 1.0)\n",
    "    k1_final[:, 0] = uc * (W - 1)\n",
    "    k1_final[:, 1] = np.clip(k1_final[:, 1], a_min=0, a_max=H - 1)\n",
    "    \n",
    "    return k0_final, k1_final, final_ids, np.empty(0, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bafb5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose01 = (p1_w2c.dot(p0_c2w)).astype(float)\n",
    "\n",
    "params = {'pose01': pose01, 'depth0': depth1,\n",
    "              'depth1': depth2, 'width': W, 'height': H,\n",
    "              'abs_tol': 0.05, 'rel_tol': 0.02}\n",
    "k0f, k1f, ids_w, _ = warp_se3_spherical(kpts1, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f2d65ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 279.28714,  377.64093],\n",
       "       [1201.1182 ,  446.01025],\n",
       "       [1468.7258 ,  496.65268],\n",
       "       ...,\n",
       "       [ 275.6683 ,  539.1186 ],\n",
       "       [1412.4904 ,  875.2244 ],\n",
       "       [1680.4025 ,  421.9269 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k0f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30dbd596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1672.21916705,  306.81269   ],\n",
       "       [ 460.1912684 ,  669.15722432],\n",
       "       [ 780.0181296 ,  610.22466507],\n",
       "       ...,\n",
       "       [1624.44552266,  432.81668533],\n",
       "       [1400.06074255,  854.0879722 ],\n",
       "       [ 947.18843201,  433.47462863]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe76c807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    3, ..., 2045, 2046, 2047])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69638330",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = cv2.resize(img1, (W, H), interpolation=cv2.INTER_LINEAR)\n",
    "img1 = cv2.resize(img2, (W, H), interpolation=cv2.INTER_LINEAR)\n",
    "canvas = 255 * np.ones((H, 2*W, 3), dtype=np.uint8)\n",
    "canvas[:, :W] = img0; canvas[:, W:] = img1\n",
    "draw_N = min(25, len(ids_w))\n",
    "sel = random.sample(range(len(ids_w)), draw_N)\n",
    "for i in sel:\n",
    "    u0, v0 = k0f[i].tolist()\n",
    "    u1, v1 = k1f[i].tolist()\n",
    "    cv2.line(canvas, (int(u0), int(v0)), (int(u1)+W, int(v1)), (0, 0, 255), 2)\n",
    "out_path = 'warp_se3_test.png'\n",
    "cv2.imwrite(str(out_path), canvas)\n",
    "logging.info(f\"Saved warp visualization to {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluefactory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
